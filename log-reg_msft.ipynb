{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Result fron logistic regression:\n",
    "\n",
    "Accuracy: 0.5240346729708432\n",
    "\n",
    "\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00       604\n",
    "           1       0.52      1.00      0.69       665\n",
    "\n",
    "    accuracy                           0.52      1269\n",
    "   macro avg       0.26      0.50      0.34      1269\n",
    "weighted avg       0.27      0.52      0.36      1269\n",
    "\n",
    "ROC AUC : 0.48058556988497736"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas_ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import holidays\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "data = \"2012-12-30\"\n",
    "\n",
    "path_stock = \"../data/stock\"\n",
    "path_fed = \"../data/fed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSFT Companies based on Market Cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSFT_df = pd.read_csv(f\"{path_stock}/MSFT_stock.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tach companies stock Data Frame processing\n",
    "- Remove the null / header\n",
    "- Make some features Engineering\n",
    "- Change the column name\n",
    "- Change the time type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def process_stock_data(df, ticker_symbol):\n",
    "    \"\"\"\n",
    "    Processes a stock data DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with stock data (Price, Close, High, Low, Open, Volume, Ticker).\n",
    "        ticker_symbol (str): Stock ticker symbol (e.g., 'AAPL').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame with calculated features and renamed columns.\n",
    "    \"\"\"\n",
    "    df.dropna(inplace=True)  # Remove rows containing any missing values.\n",
    "\n",
    "    columns_to_convert = [\"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]\n",
    "    df[columns_to_convert] = df[columns_to_convert].astype(\n",
    "        float\n",
    "    )  # Convert specified price/volume columns to floating-point numbers.\n",
    "\n",
    "    # Calculate new features based on price data:\n",
    "    df[\"delta_price\"] = (\n",
    "        df[\"High\"] - df[\"Low\"]\n",
    "    )  # Calculate the difference between the high and low price for each day.\n",
    "    df[\"avg_price\"] = (\n",
    "        df[\"Close\"] + df[\"High\"] + df[\"Low\"] + df[\"Open\"]\n",
    "    ) / 4  # Calculate the average of the close, high, low, and open prices.\n",
    "    df[\"price_ratio\"] = (\n",
    "        df[\"delta_price\"] / df[\"avg_price\"]\n",
    "    )  # Calculate the ratio of the delta price to the average price.\n",
    "    df[\"invest\"] = (\n",
    "        df[\"Volume\"] * df[\"avg_price\"]\n",
    "    )  # Calculate the difference between the trading volume and the average price (note: this might not be a standard financial metric and could be re-evaluated).\n",
    "\n",
    "    # Rename the columns for clarity and to include the ticker symbol:\n",
    "    df.rename(\n",
    "        columns={\n",
    "            \"Price\": \"date\",  # Rename the 'Price' column to 'date'.\n",
    "            \"Close\": f\"close_{ticker_symbol}\",  # Rename 'Close' to 'cl_ticker'.\n",
    "            \"High\": f\"high_{ticker_symbol}\",  # Rename 'High' to 'hi_ticker'.\n",
    "            \"Low\": f\"low_{ticker_symbol}\",  # Rename 'Low' to 'lo_ticker'.\n",
    "            \"Open\": f\"open_{ticker_symbol}\",  # Rename 'Open' to 'op_ticker'.\n",
    "            \"delta_price\": f\"delta_price_{ticker_symbol}\",  # Rename 'delta_price' to 'de_ticker'.\n",
    "            \"avg_price\": f\"avg_price_{ticker_symbol}\",  # Rename 'avg_price' to 'av_ticker'.\n",
    "            \"invest\": f\"invest_{ticker_symbol}\",  # Rename 'invest' to 'va_ticker'.\n",
    "            \"price_ratio\": f\"price_ratio_{ticker_symbol}\",  # Rename 'ratio' to 'ra_ticker'.\n",
    "            \"Volume\": f\"volume_{ticker_symbol}\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )  # Rename 'Volume' to 'Vo_ticker'.\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(\n",
    "        df[\"date\"]\n",
    "    )  # Convert the 'date' column to datetime objects for proper time series handling.\n",
    "\n",
    "    df.reset_index(\n",
    "        drop=True, inplace=True\n",
    "    )  # Reset the DataFrame's index to a default integer index and drop the original index.\n",
    "\n",
    "    # Drop the 'Ticker' column as the ticker information is now embedded in the column names:\n",
    "    if \"Ticker\" in df.columns:\n",
    "        df.drop(\"Ticker\", axis=1, inplace=True)\n",
    "\n",
    "    return df  # Return the processed DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tech companies stock clean Data Frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSFT_clean_df = process_stock_data(MSFT_df, \"MSFT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Find the Max and Min od Data column in each companies stock Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data_ranges = {}\n",
    "\n",
    "dataframes = {\"MSFT\": MSFT_clean_df}\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    if \"date\" in df.columns:\n",
    "        min_date = df[\"date\"].min()\n",
    "        max_date = df[\"date\"].max()\n",
    "        stock_data_ranges[name] = {\"min_date\": min_date, \"max_date\": max_date}\n",
    "    else:\n",
    "        print(f\"Warning: 'date' column not found in {name}_clean_df\")\n",
    "\n",
    "# Create a Pandas DataFrame to display the results\n",
    "date_range_df = pd.DataFrame.from_dict(stock_data_ranges, orient=\"index\")\n",
    "date_range_df.index.name = \"Stock\"\n",
    "\n",
    "print(date_range_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In above result , It seems that the META is started from 2012 while almost the others started from 2000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macro Indicators from Yahoo Finance:\n",
    "- Indices\n",
    "- Commodities\n",
    "- Sector ETFs (Proxies)\n",
    "- Other Market Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_df = pd.read_csv(f\"{path_stock}/macro_indicators_full.csv\")\n",
    "# Convert the 'date' column to datetime objects\n",
    "macro_df[\"Date\"] = pd.to_datetime(macro_df[\"Date\"])\n",
    "macro_df.rename(columns={\"Date\": \"date\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Frame : macro_df ---> Has some missing values that need to be check according to the time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let Filter the time after the '2012-05-31'. This is exactly after the time which we have the META stock data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_df_filter = macro_df[macro_df[\"date\"] > data]\n",
    "min_date_macro_df_filter = macro_df_filter[\"date\"].min()\n",
    "max_date_macro_df_filter = macro_df_filter[\"date\"].max()\n",
    "macro_df_filter.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# macro_df_filter = macro_df_filter.drop('Brent_Crude_Futures',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = macro_df_filter\n",
    "data_name = \"macro_df_filter\"\n",
    "# 1. Matrix Plot: Visualize the pattern of missingness\n",
    "plt.figure(figsize=(10, 6))\n",
    "msno.matrix(df)\n",
    "plt.title(f\"Missing Value Matrix - {data_name}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_clean_df = macro_df_filter.dropna()\n",
    "macro_clean_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fed Data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_df = pd.read_csv(f\"{path_fed}/combined_economic_indicators.csv\")\n",
    "\n",
    "# Rename the 'Unnamed: 0' column to 'date'\n",
    "fed_df.rename(columns={\"Unnamed: 0\": \"date\"}, inplace=True)\n",
    "\n",
    "# Convert the 'date' column to datetime objects\n",
    "fed_df[\"date\"] = pd.to_datetime(fed_df[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_df_filter = fed_df[fed_df[\"date\"] > data]\n",
    "min_date_fed_df_filter = fed_df_filter[\"date\"].min()\n",
    "max_date_fed_df_filter = fed_df_filter[\"date\"].max()\n",
    "fed_df_filter.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fed_df_filter\n",
    "data_name = \"fed_df_filter\"\n",
    "# 1. Matrix Plot: Visualize the pattern of missingness\n",
    "plt.figure(figsize=(10, 6))\n",
    "msno.matrix(df)\n",
    "plt.title(f\"Missing Value Matrix - {data_name}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_clean_df = fed_df_filter[\n",
    "    [\n",
    "        \"date\",\n",
    "        \"cpi\",\n",
    "        \"fed_rate\",\n",
    "        \"consumer_confidence\",\n",
    "        \"vix\",\n",
    "        \"oil\",\n",
    "        \"nonfarm_payrolls\",\n",
    "        \"treasury_yield\",\n",
    "        \"industrial_production\",\n",
    "        \"retail_sales\",\n",
    "        \"pmi\",\n",
    "        \"day_of_week\",\n",
    "        \"is_holiday\",\n",
    "        \"is_working_day\",\n",
    "    ]\n",
    "].dropna()\n",
    "fed_clean_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging the Date Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the first DataFrame\n",
    "merged_stock_data = AAPL_clean_df.copy()\n",
    "\n",
    "# List of stock DataFrames (excluding the first one)\n",
    "stock_dfs = [\n",
    "    MSFT_clean_df,\n",
    "    GOOGL_clean_df,\n",
    "    NVDA_clean_df,\n",
    "    AMZN_clean_df,\n",
    "    META_clean_df,\n",
    "    TSLA_clean_df,\n",
    "    AVGO_clean_df,\n",
    "    AMD_clean_df,\n",
    "    CRM_clean_df,\n",
    "]\n",
    "\n",
    "# Merge each stock DataFrame on 'date' using a left join\n",
    "for df in stock_dfs:\n",
    "    merged_stock_data = pd.merge(merged_stock_data, df, on=\"date\", how=\"inner\")\n",
    "\n",
    "# 2. Merge with Macro and Fed DataFrames\n",
    "\n",
    "# Merge stock data with macro data\n",
    "merged_data = pd.merge(\n",
    "    merged_stock_data, macro_clean_df, on=\"date\", how=\"inner\"\n",
    ")\n",
    "\n",
    "# Merge with fed data\n",
    "final_merged_df = pd.merge(merged_data, fed_clean_df, on=\"date\", how=\"inner\")\n",
    "\n",
    "stock_df = merged_stock_data\n",
    "stock_macro_df = merged_data\n",
    "stock_macro_fed_df = final_merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 10 Companies Investment over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_plot = stock_macro_fed_df[\n",
    "    [\n",
    "        \"date\",\n",
    "        \"invest_AAPL\",\n",
    "        \"invest_MSFT\",\n",
    "        \"invest_GOOGL\",\n",
    "        \"invest_NVDA\",\n",
    "        \"invest_AMZN\",\n",
    "        \"invest_META\",\n",
    "        \"invest_TSLA\",\n",
    "        \"invest_AVGO\",\n",
    "        \"invest_AMD\",\n",
    "        \"invest_CRM\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(12, 6))  # Adjust figure size for better date visibility\n",
    "\n",
    "# Plot each investment column against 'date'\n",
    "for column in stock_plot.columns:\n",
    "    if column != \"date\":  # Exclude the 'date' column from the y-axis\n",
    "        plt.plot(stock_plot[\"date\"], stock_plot[column], label=column)\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Investment Value\")\n",
    "plt.title(\"Investment over Time\")\n",
    "plt.legend(loc=\"upper left\")  # Add legend to distinguish lines\n",
    "plt.grid(True)\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federal Indicators Over Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "fed_date = stock_macro_fed_df[\n",
    "    [\n",
    "        \"date\",\n",
    "        \"cpi\",\n",
    "        \"fed_rate\",\n",
    "        \"consumer_confidence\",\n",
    "        \"vix\",\n",
    "        \"oil\",\n",
    "        \"nonfarm_payrolls\",\n",
    "        \"treasury_yield\",\n",
    "        \"industrial_production\",\n",
    "        \"retail_sales\",\n",
    "        \"pmi\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Set 'date' as index for easier plotting\n",
    "if \"date\" in fed_date.columns:\n",
    "    fed_date[\"date\"] = pd.to_datetime(fed_date[\"date\"])\n",
    "    fed_date.set_index(\"date\", inplace=True)\n",
    "else:\n",
    "    print(\"Error: 'date' column not found in fed_date DataFrame.\")\n",
    "    exit()\n",
    "\n",
    "# --- Assess Data Ranges and Scales ---\n",
    "print(\"Data Ranges and Scales:\")\n",
    "for column in fed_date.columns:\n",
    "    print(\n",
    "        f\"- {column}: Range [{fed_date[column].min():.2f}, {fed_date[column].max():.2f}], Scale: {np.ptp(fed_date[column]):.2f}\"\n",
    "    )\n",
    "\n",
    "# --- Updated Plotting with Adjusted Scale ---\n",
    "plt.figure(figsize=(15, 8))  # Increased figure size for better readability\n",
    "\n",
    "for column in fed_date.columns:\n",
    "    plt.plot(fed_date.index, fed_date[column], label=column)\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Federal Indicators Over Time (Raw Scale)\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Plotting with Standardized Scale ---\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "fed_date_scaled = fed_date.copy()\n",
    "fed_date_scaled[fed_date_scaled.columns] = scaler.fit_transform(fed_date_scaled)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "for column in fed_date_scaled.columns:\n",
    "    plt.plot(fed_date_scaled.index, fed_date_scaled[column], label=column)\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Standardized Value (Mean=0, Std=1)\")\n",
    "plt.title(\"Federal Indicators Over Time (Standardized Scale)\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macro Indicators Over Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# --- Plotting with Standardized Scale ---\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "macro_date = stock_macro_fed_df[\n",
    "    [\n",
    "        \"date\",\n",
    "        \"S&P500_Index\",\n",
    "        \"Dow_Jones_Index\",\n",
    "        \"NASDAQ_Composite\",\n",
    "        \"Russell2000_Index\",\n",
    "        \"VIX_Index\",\n",
    "        \"Dollar_Index_DXY\",\n",
    "        \"Gold_Futures\",\n",
    "        \"WTI_Oil_Futures\",\n",
    "        \"Copper_Futures\",\n",
    "        \"Brent_Crude_Futures\",\n",
    "        \"Tech_Sector_ETF\",\n",
    "        \"Energy_Sector_ETF\",\n",
    "        \"Financial_Sector_ETF\",\n",
    "        \"ConsumerDiscretionary_ETF\",\n",
    "        \"Lithium_ETF\",\n",
    "        \"Semiconductor_ETF\",\n",
    "        \"Electricity_Proxy\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Set 'date' as index for easier plotting\n",
    "if \"date\" in macro_date.columns:\n",
    "    macro_date[\"date\"] = pd.to_datetime(macro_date[\"date\"])\n",
    "    macro_date.set_index(\"date\", inplace=True)\n",
    "else:\n",
    "    print(\"Error: 'date' column not found in macro_date DataFrame.\")\n",
    "    exit()\n",
    "\n",
    "# --- Assess Data Ranges and Scales ---\n",
    "print(\"Data Ranges and Scales:\")\n",
    "for column in macro_date.columns:\n",
    "    print(\n",
    "        f\"- {column}: Range [{macro_date[column].min():.2f}, {macro_date[column].max():.2f}], Scale: {np.ptp(macro_date[column]):.2f}\"\n",
    "    )\n",
    "\n",
    "# --- Updated Plotting with Adjusted Scale ---\n",
    "plt.figure(figsize=(20, 10))  # Increased figure size for better readability\n",
    "\n",
    "for column in macro_date.columns:\n",
    "    plt.plot(macro_date.index, macro_date[column], label=column)\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Macro Indicators Over Time (Raw Scale)\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "macro_date_scaled = macro_date.copy()\n",
    "macro_date_scaled[macro_date_scaled.columns] = scaler.fit_transform(\n",
    "    macro_date_scaled\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for column in macro_date_scaled.columns:\n",
    "    plt.plot(macro_date_scaled.index, macro_date_scaled[column], label=column)\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Standardized Value (Mean=0, Std=1)\")\n",
    "plt.title(\"Macro Indicators Over Time (Standardized Scale)\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install Jinja2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSFT_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSFT_clean_df.to_csv(\"../data/stock/MSFT_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# “1” if next day’s close is higher than today’s, else “0”\n",
    "MSFT_clean_df[\"Target\"] = (\n",
    "    MSFT_clean_df[\"close_MSFT\"].shift(-1) > MSFT_clean_df[\"close_MSFT\"]\n",
    ").astype(int)\n",
    "MSFT_clean_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-day and 20-day moving averages\n",
    "MSFT_clean_df[\"MA5\"] = MSFT_clean_df[\"close_MSFT\"].rolling(5).mean()\n",
    "MSFT_clean_df[\"MA20\"] = MSFT_clean_df[\"close_MSFT\"].rolling(20).mean()\n",
    "\n",
    "# Momentum: percentage change over the last 5 days\n",
    "MSFT_clean_df[\"Mom5\"] = MSFT_clean_df[\"close_MSFT\"].pct_change(5)\n",
    "\n",
    "# Daily volatility: high-low range as a fraction\n",
    "MSFT_clean_df[\"volume_MSFT\"] = (\n",
    "    MSFT_clean_df[\"high_MSFT\"] - MSFT_clean_df[\"low_MSFT\"]\n",
    ") / MSFT_clean_df[\"open_MSFT\"]\n",
    "\n",
    "MSFT_clean_df.dropna(inplace=True)\n",
    "X = MSFT_clean_df[[\"MA5\", \"MA20\", \"Mom5\", \"volume_MSFT\"]]\n",
    "y = MSFT_clean_df[\"Target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False  # no shuffling for time series\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             roc_auc_score)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC :\", roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the probability outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "prec, rec, thresh = precision_recall_curve(y_test, probs)\n",
    "# choose threshold that balances precision & recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class weighting or resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature enrichment\n",
    "\n",
    "    Your four indicators (MA5, MA20, Mom5, Vol) may not capture enough signal.\n",
    "\n",
    "    Try adding:\n",
    "\n",
    "        Momentum over different horizons (1-, 10-day)\n",
    "\n",
    "        Oscillators (RSI, Stochastic)\n",
    "\n",
    "        Volume-based features (on-balance volume, VWAP)\n",
    "\n",
    "        Calendar effects (day-of-week, month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization & hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\"C\": [0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(\n",
    "    LogisticRegression(class_weight=\"balanced\"), param_grid, cv=5\n",
    ")\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better evaluation\n",
    "\n",
    "    Use walk-forward cross-validation (rolling window) to mimic live trading.\n",
    "\n",
    "    Track confusion matrices to see trade-offs, not just accuracy.\n",
    "\n",
    "    Consider profit-based metrics (e.g. Sharpe ratio) instead of pure classification metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Try flipping your predictions and recalculating AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, 1 - probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Close price with MA5 & MA20\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(MSFT_clean_df.index, MSFT_clean_df[\"close_MSFT\"], label=\"Close\")\n",
    "plt.plot(y_test.index, y_pred, label=\"Close_pred\")\n",
    "plt.plot(MSFT_clean_df.index, MSFT_clean_df[\"MA5\"], label=\"5-Day MA\")\n",
    "plt.plot(MSFT_clean_df.index, MSFT_clean_df[\"MA20\"], label=\"20-Day MA\")\n",
    "plt.title(\"MSFT Close Price with 5-Day & 20-Day Moving Averages\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price (USD)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Close price with MA5 & MA20\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(MSFT_clean_df.index, MSFT_clean_df[\"close_MSFT\"], label=\"Close\")\n",
    "plt.plot(MSFT_clean_df.index, MSFT_clean_df[\"MA5\"], label=\"5-Day MA\")\n",
    "plt.plot(MSFT_clean_df.index, MSFT_clean_df[\"MA20\"], label=\"20-Day MA\")\n",
    "plt.title(\"MSFT Close Price with 5-Day & 20-Day Moving Averages\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price (USD)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. 5-Day Momentum\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(MSFT_clean_df.index, MSFT_clean_df[\"Mom5\"])\n",
    "plt.title(\"MSFT 5-Day Momentum\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Momentum (% Change)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Daily Volatility (High-Low)/Open\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(MSFT_clean_df.index, MSFT_clean_df[\"volume_MSFT\"])\n",
    "plt.title(\"MSFT Daily Volatility (High-Low)/Open\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Volatility\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
